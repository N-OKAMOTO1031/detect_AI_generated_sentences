{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYZRdu_z-rMV",
        "outputId": "68887f0d-e452-4ebc-a743-03efadda748a"
      },
      "outputs": [],
      "source": [
        "!pip install -q git+https://github.com/huggingface/transformers\n",
        "# !pip install transformers\n",
        "!pip install -q  sentencepiece\n",
        "!pip install -q  torchinfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9IHO13wzD7qT"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import torch\n",
        "import glob\n",
        "from tqdm import tqdm\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D5AtwVydNhNt"
      },
      "outputs": [],
      "source": [
        "# 保存してあるwikipediaのタイトルのjsonをロード\n",
        "json_path = 'wiki_title_dict.json'\n",
        "with open(json_path) as f:\n",
        "    wiki_ds_json = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8fH6a232FK7_"
      },
      "outputs": [],
      "source": [
        "def get_llm_sentence(input_text, generator, tokenizer):\n",
        "  try:\n",
        "    text = generator(\n",
        "        f\"ユーザー: {input_text}\\nシステム: \",\n",
        "        max_length = 400,\n",
        "        do_sample = True,\n",
        "        temperature = 0.7,\n",
        "        top_p = 0.9,\n",
        "        top_k = 0,\n",
        "        repetition_penalty = 1.1,\n",
        "        num_beams = 1,\n",
        "        pad_token_id = tokenizer.pad_token_id,\n",
        "        num_return_sequences = 1,\n",
        "    )\n",
        "    sentence = text[0]['generated_text'].split('システム:  ')[-1].replace('\\n', '')\n",
        "    return sentence\n",
        "  except Exception as e:\n",
        "    print(input_text)\n",
        "    print(e)\n",
        "    try:\n",
        "      print(text)\n",
        "\n",
        "    except:\n",
        "      pass\n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKfZYVM0fWI2",
        "outputId": "3cc1fa06-a90f-4a4e-e0c0-b2d5d5e0bafe"
      },
      "outputs": [],
      "source": [
        "# tokenizerとmodelを設定\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"line-corporation/japanese-large-lm-3.6b-instruction-sft\", use_fast=False)\n",
        "model = AutoModelForCausalLM.from_pretrained(\"line-corporation/japanese-large-lm-3.6b-instruction-sft\")\n",
        "if device == 'cuda':\n",
        "  model.cuda()\n",
        "generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u6iK_hcfzMds"
      },
      "outputs": [],
      "source": [
        "title_list = wiki_ds_json['title']\n",
        "n = 100\n",
        "split_title_list = [title_list[idx:idx + n] for idx in range(0,len(title_list), n)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-vrIcsyoGi4U"
      },
      "outputs": [],
      "source": [
        "# すでに出力済みのファイルを探索\n",
        "finished_ds_path_list = glob.glob('llm_sentence/*.json')\n",
        "\n",
        "# ファイルがあれば終了済みの番号を取得\n",
        "if len(finished_ds_path_list) != 0:\n",
        "  finished_number_list = [int(i.split('/')[-1].split('.')[0].split('_')[-1]) for i in finished_ds_path_list if ('(' not in i)and (')' not in i)]\n",
        "  no_file = False\n",
        "\n",
        "# 無ければフラグをTrueに\n",
        "else:\n",
        "  no_file = True\n",
        "\n",
        "# 開始番号を設定\n",
        "if no_file:\n",
        "  start_number = 0\n",
        "else:\n",
        "  start_number = max(finished_number_list)+1\n",
        "number = start_number\n",
        "\n",
        "# LLMの回答を取得\n",
        "while len(split_title_list[start_number:])!=0:\n",
        "  llm_sentence_dict = {}\n",
        "\n",
        "  # 番号を予約\n",
        "  path = f'llm_sentence_{number}.json'\n",
        "  json_file = open(path, mode=\"w\")\n",
        "  json.dump(llm_sentence_dict, json_file, indent=2)\n",
        "  json_file.close()\n",
        "\n",
        "  title_list = split_title_list[number]\n",
        "\n",
        "  for title in tqdm(title_list):\n",
        "    input_text = f\"{title}に関して、wikipediaの概要を真似て300文字程度で説明してください。\"\n",
        "    llm_sentence_dict[title] = get_llm_sentence(input_text, generator, tokenizer)\n",
        "\n",
        "  path = f'llm_sentence_{number}.json'\n",
        "  json_file = open(path, mode=\"w\")\n",
        "  json.dump(llm_sentence_dict, json_file, indent=2)\n",
        "  json_file.close()\n",
        "\n",
        "  # 結果を保存\n",
        "  finished_ds_path_list = glob.glob('llm_sentence/*.json')\n",
        "  finished_number_list = [int(i.split('/')[-1].split('.')[0].split('_')[-1]) for i in finished_ds_path_list if ('(' not in i)and (')' not in i)]\n",
        "  start_number = max(finished_number_list)+1\n",
        "  number = start_number"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
