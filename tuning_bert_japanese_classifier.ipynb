{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PuJ3jtflPc3c",
        "outputId": "cea9c862-9a5c-4b0f-acb0-dea0f070bba7"
      },
      "outputs": [],
      "source": [
        "!pip install -q git+https://github.com/huggingface/transformers\n",
        "!pip install -q  sentencepiece\n",
        "!pip install -q mecab-python3\n",
        "!pip install -q fugashi\n",
        "!pip install -q ipadic\n",
        "!apt install aptitude swig\n",
        "!aptitude install mecab libmecab-dev mecab-ipadic-utf8 git make curl xz-utils file -y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cmals36LPkTo"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VKC0IC2NPu0j"
      },
      "outputs": [],
      "source": [
        "ai_sentence = pd.read_csv('https://raw.githubusercontent.com/N-OKAMOTO1031/datasets/main/detect_AI_generated_sentences/main_verification/llm_summary.csv')\n",
        "wikipedia_sentence = pd.read_csv('https://raw.githubusercontent.com/N-OKAMOTO1031/datasets/main/detect_AI_generated_sentences/main_verification/wikipedia_summary.csv')\n",
        "ai_sentence['label'] = 1\n",
        "ai_sentence['label_name'] = 'ai_generated_sentence'\n",
        "ai_sentence = ai_sentence.drop('title', axis=1)\n",
        "\n",
        "wikipedia_sentence['label'] = 0\n",
        "wikipedia_sentence['label_name'] = 'human_generated_sentence'\n",
        "wikipedia_sentence = wikipedia_sentence.drop('title', axis=1)\n",
        "\n",
        "sentence_df = pd.concat([ai_sentence, wikipedia_sentence]).dropna()\n",
        "\n",
        "sentences = sentence_df.sentence.values\n",
        "labels = sentence_df.label.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "82KAtXndWlBN"
      },
      "outputs": [],
      "source": [
        "from transformers import BertJapaneseTokenizer\n",
        "# tokenizerを設定\n",
        "tokenizer = BertJapaneseTokenizer.from_pretrained('cl-tohoku/bert-base-japanese-whole-word-masking')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ncl0HpRYkRi1",
        "outputId": "3fad1d7d-af52-4597-9b69-dda87147f4db"
      },
      "outputs": [],
      "source": [
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# 1文づつ処理\n",
        "for sent in tqdm(sentences):\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,\n",
        "                        add_special_tokens = True,\n",
        "                        max_length =512,\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,\n",
        "                        return_tensors = 'pt',\n",
        "                   )\n",
        "\n",
        "    # 単語IDを取得\n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "\n",
        "    # Attention　maskの取得\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# リストに入ったtensorを縦方向（dim=0）へ結合\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "\n",
        "# tenosor型に変換\n",
        "labels = torch.tensor(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Y4YfbSmk-Du",
        "outputId": "8b494627-44f6-4d58-d8da-82cc7c7db3b9"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# データセットクラスの作成\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "# 90%地点のIDを取得\n",
        "val_size = int(0.1 * len(dataset))\n",
        "test_size = int(0.1 * len(dataset))\n",
        "train_size = len(dataset) - val_size - test_size\n",
        "\n",
        "# データセットを分割\n",
        "train_dataset, val_dataset, test_datasets = random_split(dataset, [train_size, val_size, test_size])\n",
        "\n",
        "print('訓練データ数：{}'.format(train_size))\n",
        "print('検証データ数: {} '.format(val_size))\n",
        "print('testデータ数: {} '.format(test_size))\n",
        "\n",
        "# データローダーの作成\n",
        "batch_size = 32\n",
        "\n",
        "# 訓練データローダー\n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,\n",
        "            sampler = RandomSampler(train_dataset), # ランダムにデータを取得してバッチ化\n",
        "            batch_size = batch_size\n",
        "        )\n",
        "\n",
        "# 検証データローダー\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset,\n",
        "            sampler = SequentialSampler(val_dataset), # 順番にデータを取得してバッチ化\n",
        "            batch_size = batch_size\n",
        "        )\n",
        "\n",
        "# テストデータローダー\n",
        "test_dataloader = DataLoader(\n",
        "            test_datasets,\n",
        "            sampler = SequentialSampler(test_datasets), # 順番にデータを取得してバッチ化\n",
        "            batch_size = batch_size\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1uXyfRkk_HJ",
        "outputId": "dee650dd-7a48-421c-bb8e-e90f14c97342"
      },
      "outputs": [],
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# BertForSequenceClassification 学習済みモデルのロード\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"cl-tohoku/bert-base-japanese-whole-word-masking\",\n",
        "    num_labels = 2,\n",
        "    output_attentions = False,\n",
        "    output_hidden_states = False,\n",
        "    # use_auth_token = True\n",
        ")\n",
        "\n",
        "# モデルをGPUへ転送\n",
        "if device == 'cuda':\n",
        "  model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sl9B04tcIDWv",
        "outputId": "c18a887a-483c-4820-ace4-8f117ac01fa9"
      },
      "outputs": [],
      "source": [
        "# 最適化手法の設定\n",
        "optimizer = AdamW(model.parameters(), lr=2e-6)\n",
        "\n",
        "# 訓練パートの定義\n",
        "def train(model, dataloader):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    for batch in train_dataloader:\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        optimizer.zero_grad()\n",
        "        loss= model(b_input_ids,\n",
        "                             token_type_ids=None,\n",
        "                             attention_mask=b_input_mask,\n",
        "                             labels=b_labels).loss\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "    return train_loss\n",
        "\n",
        "# テストパートの定義\n",
        "def validation(model, dataloader):\n",
        "    model.eval()# 訓練モードをオフ\n",
        "    val_loss = 0\n",
        "    with torch.no_grad(): # 勾配を計算しない\n",
        "        for batch in dataloader:\n",
        "            b_input_ids = batch[0].to(device)\n",
        "            b_input_mask = batch[1].to(device)\n",
        "            b_labels = batch[2].to(device)\n",
        "            with torch.no_grad():\n",
        "                loss = model(b_input_ids,\n",
        "                                    token_type_ids=None,\n",
        "                                    attention_mask=b_input_mask,\n",
        "                                    labels=b_labels).loss\n",
        "            val_loss += loss.item()\n",
        "    return val_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "aPxyqfz3IMsw",
        "outputId": "cc99c29f-ccb8-4bb3-9438-371fc4bd4a89"
      },
      "outputs": [],
      "source": [
        "# 学習の実行\n",
        "max_epoch = 50\n",
        "train_loss_ = []\n",
        "valid_loss_ = []\n",
        "\n",
        "for epoch in tqdm(range(max_epoch)):\n",
        "  print(epoch)\n",
        "  train_ = train(model, train_dataloader)\n",
        "  valid_ = validation(model, validation_dataloader)\n",
        "  train_loss_.append(train_)\n",
        "  valid_loss_.append(valid_)\n",
        "  print(train_)\n",
        "  print(valid_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnobzOuC-B6E",
        "outputId": "75d51b69-9fdd-46d8-8712-9741acaae7c2"
      },
      "outputs": [],
      "source": [
        "train_loss_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tr_C8qL29-n0",
        "outputId": "207c918b-aa39-492e-b237-c051ce271a33"
      },
      "outputs": [],
      "source": [
        "valid_loss_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S5r9w1_-K0oe"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "model.eval()# 訓練モードをオフ\n",
        "prediction_result_df = pd.DataFrame()\n",
        "for batch in test_dataloader:\n",
        "  b_input_ids = batch[0].to(device)\n",
        "  b_input_mask = batch[1].to(device)\n",
        "  b_labels = batch[2].to(device)\n",
        "  with torch.no_grad():\n",
        "      # 学習済みモデルによる予測結果をpredsで取得\n",
        "      preds = model(b_input_ids,\n",
        "                          token_type_ids=None,\n",
        "                          attention_mask=b_input_mask)\n",
        "  # pd.dataframeへ変換（GPUに乗っているTensorはgpu->cpu->numpy->dataframeと変換）\n",
        "  logits_df = pd.DataFrame(preds[0].cpu().numpy(), columns=['logit_0', 'logit_1'])\n",
        "  ## np.argmaxで大き方の値を取得\n",
        "  pred_df = pd.DataFrame(np.argmax(preds[0].cpu().numpy(), axis=1), columns=['pred_label'])\n",
        "  label_df = pd.DataFrame(b_labels.cpu().numpy(), columns=['true_label'])\n",
        "\n",
        "  accuracy_df = pd.concat([logits_df, pred_df, label_df], axis=1)\n",
        "\n",
        "  prediction_result_df = pd.concat([prediction_result_df, accuracy_df])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "DDM_Cz-UAyj-",
        "outputId": "a1dbf973-f4eb-41e9-b2ab-532cc1e6450a"
      },
      "outputs": [],
      "source": [
        "prediction_result_df.loc[prediction_result_df['pred_label'] != prediction_result_df['true_label']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T0tyV9g0vx8T"
      },
      "outputs": [],
      "source": [
        "# モデルの保存\n",
        "model.save_pretrained('model/model')\n",
        "model.save_pretrained('model/tokenizer')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
